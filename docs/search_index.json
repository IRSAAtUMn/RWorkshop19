[
["index.html", "Introduction to Reproducible Data Science with R Home", " Introduction to Reproducible Data Science with R Institute for Research in Statistics and its Applications at the University of Minnesota Home With the increasing availability of data with broad applications (and the sheer size of some of these data), it is more important than ever to be able to elucidate trends, decisions, and stories from data. Our team will offer a hands-on introduction to data science and statistics using the free and publicly available software R. Assuming no background in software or statistics, we will introduce you to some of the most useful, modern, and popular data analysis techniques. TOPICS COVERED: Features of R and best practices for reproducible data science Constructing visualizations, wrangling data, and producing simple numerical summaries A gentle introduction to statistical modeling The material herein is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],
["welcome-set-up.html", "Welcome &amp; Set-Up", " Welcome &amp; Set-Up Welcome to IRSA’s “Introduction to Reproducible Data Science with R”! As you get settled in, please take the following steps to get set up for the workshop: Introduce yourself to &amp; meet the other students at your table. Though workshop helpers will be floating around the room, we encourage you to support one another as you learn R. Open the workshop manual: https://irsaatumn.github.io/RWorkshop19/ Open RStudio. Within RStudio, type the following into the console (lower left panel): library(&quot;rmarkdown&quot;) library(&quot;knitr&quot;) library(&quot;ggplot2&quot;) library(&quot;dplyr&quot;) library(&quot;fivethirtyeight&quot;) library(&quot;car&quot;) library(&quot;glmbb&quot;) library(&quot;pacman&quot;) library(&quot;RColorBrewer&quot;) If you get any errors, this likely means that you have not yet installed the packages listed in the participant checklist. If this is the case, type the following into the console: install.packages(c(&quot;RColorBrewer&quot;, &quot;knitr&quot;, &quot;car&quot;, &quot;ggplot2&quot;, &quot;fivethirtyeight&quot;, &quot;glmbb&quot;, &quot;pacman&quot;, &quot;rmarkdown&quot;, &quot;dplyr&quot;)) "],
["introduction-to-r-and-rstudio.html", " 1 Introduction to R and RStudio 1.1 Getting Started 1.2 R Studio Overview 1.3 R script", " 1 Introduction to R and RStudio Author: Alicia Hofelich Mohr .col2 { columns: 2 200px; /* number of columns and width in pixels*/ -webkit-columns: 2 200px; /* chrome, safari */ -moz-columns: 2 200px; /* firefox */ } This workshop is motivated by the increasing need for tools that can be used to elucidate trends, decisions, and stories from data. This practice is broadly referred to as “data science”: source: Wickham &amp; Grolemund: R for Data Science This workflow is often iterative and to ensure we can trust the outcomes, the process between input and output should be transparent and repeatable. Workshop Outline &amp; Goals Our goal is to provide a hands on introduction to navigating the data science pipeline with R. You will walk away with a solid foundation upon which you can build for your own research. Day 1: Introduction to R &amp; RStudio Reproducibility and R Markdown Data Visualization Simple Data Wrangling and Summaries Day 2: Linear Regression Logistic Regression 1.1 Getting Started No matter what data you are working with, you need software to explore and construct inferences from these data. In this workshop, we’ll use the R statistical software. Why R? it’s free it’s open source it’s flexible / useful for a wide variety of applications it has a huge online community it can be used to create reproducible documents, apps, books, etc. (In fact, this document was constructed within RStudio.) R and RStudio Before this workshop, you were asked to download/update both R and RStudio. What’s the difference? https://mirror.las.iastate.edu/CRAN/ Actual program (engine) Can create and run scripts directly in R Text editing on a Mac https://www.rstudio.com/products/rstudio/download/ Integrated Development Environment (IDE) for R Text editing for Mac and PC Easy integration with R Markdown, Shiny, git, etc 1.2 R Studio Overview Note that when you first open RStudio, you will only see three windows (because you won’t have any scripts or files open yet). 1.2.1 The R console The R console is where R commands are executed and most output will be displayed. You can type commands directly into the console and run them by pressing “enter”. Using R as a calculator We can use R as a basic calculator. Try typing and running each of the following into the console. 2 + 3 2 * 3 2^3 (2 + 3)^2 2 + 3^2 Assignment We can assign and store R output as objects in R’s environment. This allows us to use or reference the output later. Store the result of 2 + 3^2 as my_result my_result &lt;- 2 + 3^2 Tip: press ‘cmd+enter’ on a Mac and ‘cntl+enter’ to create the assign arrow Once you create an object, you will see it appear in the “Environment” pane. Check out the result in the console my_result Do something with the results my_result + 5 Update the object my_result &lt;- my_result + 5 my_result Object names can not include spaces or start with numbers! my result &lt;- 2 + 3^2 1result &lt;- 2 + 3^2 Functions R also has built in functions that take in arguements and return an output: function(arguments). Arugments can be objects, numbers, or text. sqrt(9) sqrt(my_result) The sum() function calculates the sum of the listed numbers. Does the order of arguments matter? sum(2, 3) sum(3, 2) What does the rep() function do? Does the order of arguments matter? rep(2, 3) rep(3, 2) Arguments have names rep(x = 3, times = 2) rep(times = 2, x = 3) Is R case sensitive? eg: Can we spell rep() as Rep()? Rep(2, 3) 1.2.2 The Help window How do you know what a function does, what arguments are available, and what they are named? Look in the help window! You can find the help page for a function by typing the function name in the search bar Or by typing “?” followed by the function name in the console ?rep() If you are not sure of what a function would be called or whether it exists, a great option is to Google it. Some helpful sites include: Stack Overflow: http://stackoverflow.com/questions/tagged/r R bloggers: http://www.r-bloggers.com/ Quick-R: http://www.statmethods.net/ 1.2.3 The Package window Functions such as rep() and sum() (along with many others) are built into R’s base. These sets of functions are often referred to as “base R”. However, because R is open source, anyone can contribute extra functions to R (which allow you to do more things) - these extra functions are bundled into “packages” and are typically hosted in the CRAN repository. To install the package from CRAN to your computer, you can click “Install” in the package tab, which opens a pop-up window. Or use install.packages() in the console install.packages(&quot;ggplot2&quot;) You only need to install packages once for each computer/version of R. To access the functions in R, you need to load the packages with the library() command each time start a new R session. library(ggplot2) Note: There are MANY ways to do the same thing in R. For example, cronbach’s alpha (a common measure of internal scale consistency) is not built into base R. psych package: alpha() psy package: cronbach() ltm package: cronbach.alpha() fmsb package: CronbachAlpha() epiDisplay package: alpha() 1.2.4 The Environment window Objects we create in R are stored in the Environment tab. If this gets cluttered and you want to “start fresh”, you can clear the environment: Click on the “broom” icon: Or type into the console: rm(list=ls()) 1.2.5 The History window This window provides a list of all the commands you have entered in the console While this can serve as a nice reminder of what you have done, think about how well you will remember what all this means tomorrow. Or six months from now. For procedures you care about (for example, anything with data), you will want to capture what you do in an R script. 1.3 R script To open a new script, select File –&gt; New File –&gt; R Script R scripts Contain R code for a given analysis/project (just as you would type it in the console) Include comments (R ignores lines starting with #) Can be run line by line (“run”) or all at once (“source”) Need to be written in order (i.e., code to create an object needs to come before code that uses the object) Let’s prep our R script for data exploration. You can use comments to describe what lines of code do, or as breaks to set apart information about the script from the script itself. ###################################### ## Intro to R Workshop ## ## 2019-08-14 ###################################### You can run code from a script in the console by pressing “cmd+enter” (Mac) or “cntl+enter” (PC) # Calculate 3 squared 3^2 1.3.1 Working with data The follow data were used in FiveThirtyEight’s article “Some People Are Too Superstitious To Have A Baby On Friday The 13th”, which analyzes rates of scheduled births on the 13th of the month. This analysis uses the following data: Data Structure Tidy data tables have two key features: Each row represents a single observational unit of the sample. Each column represents a variable, ie. an attribute of the cases. There are no extras in the dataset - no row summaries, column summaries, data entry notes, comments, graphs, etc. All comments about the data collection, variables, etc should be provided in a separate codebook. Question: What are the units of observation in the above data? What are the variables? Importing Data You can read data into R from a file on your computer, a dataset on the internet, or use data that are included in a package in R. Luckily for us, the Friday the 13th data are already stored within R in the fivethirtyeight package. IF AND ONLY IF you did not install the fivethirtyeight package before the workshop, you can do so now by typing the following code in the console: install.packages(&quot;fivethirtyeight&quot;, dependencies = TRUE) You only need to install a package one time for a given computer and version of R. However, each time you want to use functions or data in a package, you will need to load the package into R. Put the following code in your script: library(fivethirtyeight) data(US_births_2000_2014) To learn more about this data, you can access codebook information: ?US_births_2000_2014 Examining data structure in R Before we do any analysis, we have to understand the structure of our data. Try each of the following by typing them into your script and running them: # View the data table in a separate tab View(US_births_2000_2014) # Check out the first rows in the console head(US_births_2000_2014) # Obtain the data dimensions: rows x columns dim(US_births_2000_2014) # Get the variable names names(US_births_2000_2014) # Look at summary information for each variable summary(US_births_2000_2014) Examining specific variables # Access a single variable using &quot;$&quot; US_births_2000_2014$year US_births_2000_2014$month # Determine levels/categories of categorical variables levels(factor(US_births_2000_2014$year)) levels(factor(US_births_2000_2014$day_of_week)) Subsetting datasets We can take subsets of observations in the data that satisfy a criterion defined by a variable in the dataset: # Subset of dates that fell on a Friday fridays &lt;- subset(US_births_2000_2014, US_births_2000_2014$day_of_week == &quot;Fri&quot;) dim(fridays) summary(fridays) # Subset of dates that were on the 13th of the month thirteens &lt;- subset(US_births_2000_2014, US_births_2000_2014$date_of_month == &quot;13&quot;) dim(thirteens) summary(thirteens) # Subset of dates that were on the 13th AND a Friday fridays13 &lt;- subset(US_births_2000_2014, US_births_2000_2014$day_of_week == &quot;Fri&quot; &amp; US_births_2000_2014$date_of_month == &quot;13&quot;) dim(fridays13) summary(fridays13) # Subset of dates that were on the 13th OR a Friday fridays_or_13 &lt;- subset(US_births_2000_2014, US_births_2000_2014$day_of_week == &quot;Fri&quot; | US_births_2000_2014$date_of_month == &quot;13&quot;) dim(fridays_or_13) summary(fridays_or_13) Some useful syntax for subsetting: &lt; (less than), &lt;= (less than or equal to), &gt; (greater than), &gt;= (greater than or equal to), == (equal to) &amp; (and), | (or) Exercises Let’s apply the above tools to the bechdel data in the fivethirtyeight package. This data was used in the fivethirtyeight.com’s article “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women” which analyzes movies that do/don’t pass the Bechdel test. A movie passes the test if it meets the following criteria: there are \\(\\ge 2\\) female characters the female characters talk to each other at least 1 time, they talk about something other than a male character Load the data into your environment and examine the codebook information. View the dataset in a separate tab. Check out the first 6 cases of the data. What are the units of observation (rows)? How many rows/columns does this dataset have? What are the names of the variables? Access the variable clean_test alone. What are the levels of this variable? Create a subset of the data that contain only movies that fail the bechdal test. Store this as failures. How many rows does this subset contain? Create a subset of the data that contain movies with a 2013 budget under one million dollars. Store this subset as cheap. How many rows does this subset contain? Solutions: #1. Load the data into your environment and examine the codebook information. library(fivethirtyeight) data(&quot;bechdel&quot;) ?bechdel #2. View the dataset in a separate tab. View(bechdel) #3. Check out the first 6 cases of the data. head(bechdel) #4. What are the units of observation (rows)? # each row = a movie #5. How many rows/columns does this dataset have? dim(bechdel) #6. What are the names of the variables? names(bechdel) #7. Access the variable `clean_test` alone. What are the levels of this variable? bechdel$clean_test levels(factor(bechdel$clean_test)) #8. Create a subset of the data that contain only movies that fail the bechdal test. Store this as `failures`. How many rows does this subset contain? failures &lt;- subset(bechdel, bechdel$binary == &quot;FAIL&quot;) dim(failures) #9. Create a subset of the data that contain movies with a 2013 budget under one million dollars. Store this subset as `cheap`. How many rows does this subset contain? cheap &lt;- subset(bechdel, bechdel$budget_2013 &lt; 1000000) "],
["reproducible-reports-with-rmarkdown.html", " 2 Reproducible Reports with RMarkdown", " 2 Reproducible Reports with RMarkdown Author: Alicia Hofelich Mohr .col2 { columns: 2 200px; /* number of columns and width in pixels*/ -webkit-columns: 2 200px; /* chrome, safari */ -moz-columns: 2 200px; /* firefox */ } "],
["understanding-data-visualization.html", " 3 Understanding data: Visualization 3.1 Goal: Understanding Through Visualizations 3.2 ggplot 3.3 Univariate visualizations 3.4 Visualizing relationships 3.5 Exercises", " 3 Understanding data: Visualization Author: Alicia Johnson 3.1 Goal: Understanding Through Visualizations In this module we’ll focus on the “Visualise” step in the data science workflow: source: Wickham &amp; Grolemund: R for Data Science Reconsider and import the US_births_2000_2014 data in the fivethirtyeight package: library(fivethirtyeight) data(&quot;US_births_2000_2014&quot;) # Give the data a shorter nickname birth_data &lt;- US_births_2000_2014 We investigated the basic structure of this tidy data set in the previous activity. Now we can start to ask some research questions to better understand the data: What’s the typical number of births per day? To what degree do the number of births vary from day to day? Is there a relationship between the number of births and time of year? Between the number of births and day of week? Is there any evidence that people are too superstitious to give birth on Friday the 13th? Visualizing the data is the first natural step in answering these questions. Why? Visualizations help us understand what we’re working with: What are the scales of our variables? Are there any outliers, i.e. unusual cases? What are the patterns among our variables? This understanding will inform our next steps: What statistical tool / model is appropriate? Once our analysis is complete, visualizations are a powerful way to communicate our findings and tell a story. 3.2 ggplot We’ll construct visualizations using the ggplot function in RStudio. Though the ggplot learning curve can be steep, its “grammar” is intuitive and generalizable once mastered. The ggplot plotting function is stored in the ggplot2 package: library(ggplot2) The best way to learn about ggplot is to just play around. Don’t worry about memorizing the syntax. Rather, focus on the patterns and potential of their application. There’s a helpful cheat sheet for future reference: GGPLOT CHEAT SHEET 3.3 Univariate visualizations Our primary variable of interest in the birthday data is the quantitative births variable which summarizes the number of U.S. births on each individual day between 2000 and 2014. Before examining the relationship between births and any other variable, it’s important to develop an understanding of the univariate patterns. We’ll explore 2 of many methods for visualizing quantitative variables: histograms &amp; density plots. 3.3.1 Histograms A histogram is constructed by (1) dividing up the observed range of the variable into ‘bins’ of equal width; and (2) counting up the number of cases that fall into each bin. Try out the code below. Construct a histogram for the 2014 births Try out the code below that builds up from a simple to a customized histogram. At each step determine how each piece of code contributes to the plot. # Focus first on just the 2014 data library(dplyr) only_2014 &lt;- birth_data %&gt;% filter(year == 2014) # Set up a plotting frame ggplot(only_2014, aes(x = births)) # Add a histogram layer ggplot(only_2014, aes(x = births)) + geom_histogram() # Change the border colors ggplot(only_2014, aes(x = births)) + geom_histogram(color = &quot;white&quot;) Examine the histogram Based on the histogram alone… Examine the trend: roughly, what’s the typical number of births per day? Examine the variability: roughly, what was the smallest number of births? The largest? Describe the shape of the histogram? Do you have any guesses about what explains this shape? How wide are the births bins? What was the most common bin? On roughly how many days did the number of births fall into this bin? Tune the histogram The bin size used above was the default selected by RStudio. Below, change the bin width and reflect upon how this impacts the visualization. Specifically, explain why selecting bin width is a Goldilocks problem – we don’t want the bins to be too narrow or too wide, but just right. # Decrease bin width ggplot(only_2014, aes(x = births)) + geom_histogram(color = &quot;white&quot;, binwidth = 30) # Increase bin width ggplot(only_2014, aes(x = births)) + geom_histogram(color = &quot;white&quot;, binwidth = 2500) You try Construct a histogram of births using the entire birth_data which spans from 2000 to 2014. How, if at all, do the trends and variability in births across all of these years compare to those in 2014 alone? In summary, you constructed: 3.3.2 Density plots A density plot is essentially a smooth version of the histogram. Instead of sorting cases into discrete bins, the “density” of cases is calculated across the entire range of values. The greater the number of cases, the greater the density! The density is then scaled so that the area under the density curve always equals 1 and the area under any fraction of the curve represents the fraction of cases that lie in that range. Construct a density plot for the 2014 births # Set up the plotting frame ggplot(only_2014, aes(x = births)) # Add a density curve ggplot(only_2014, aes(x = births)) + geom_density() Examine the density plot for the 2014 births Does this visualization provide any information that the histogram doesn’t? Which do you prefer for visualizing the births data, the density plot or histogram? Why? In summary, you constructed: 3.4 Visualizing relationships Consider the data on just the first 6 days of 2014: We saw some goofy patterns in the births data. Perhaps this might be explained by day of year, month, or day of week. However, before constructing graphics of the relationships among these variables, we need to understand what features these graphics should have. Challenge yourself to think about how we might visualize the relationships among the following sets of variables: births vs date births vs day_of_week births vs date and day_of_week (in 1 plot) 3.4.1 Quantitative vs quantitative Scatterplots of 2 quantitative variables Let’s start by visualizing the relationship between the number of daily births and the date or day of year for the 2014 births data. We can think of both as quantitative variables. In order to visualize their numerical scales, both variables need an axis. On these axes, we can represent each row (day) by a dot. # Just a graphics frame ggplot(only_2014, aes(y = births, x = date)) # Add a scatterplot layer ggplot(only_2014, aes(y = births, x = date)) + geom_point() You try Construct a scatterplot of births vs date using the 2000-2014 birth_data. Examine the scatterplots Do you observe any s(easonal trends? If so, at what time of year do births tend to be the highest? The lowest? Any other strange patterns? What do you think might explain these patterns? Visualize the trend Finally, we can add a visual summary of the trend in births by date. Explain why this isn’t very helpful in this particular example. # Add a smooth trend line ggplot(only_2014, aes(y = births, x = date)) + geom_point() + geom_smooth() In summary: 3.4.2 Quantitative vs categorical Next, consider the relationship between births (quantitative) and day_of_week (categorical). Since day_of_week is categorical, visualizing this variable requires a visual grouping mechanism. We’ll consider a couple approaches. Construct side-by-side plots Again focus on the general patterns in the syntax and how we’ve changed the earlier code. # Density plots by group ggplot(only_2014, aes(x = births, fill = day_of_week)) + geom_density() # To see better: add transparency ggplot(only_2014, aes(x = births, fill = day_of_week)) + geom_density(alpha = 0.5) # Or use boxplots! ggplot(only_2014, aes(x = day_of_week, y = births)) + geom_boxplot() Interpreting the side-by-side plots What do the side-by-side plots reveal about birth patterns? Which day tends to see the fewest births? The greatest? There are some outliers here. What do you suspect explains these outliers? In summary: 3.4.3 Quantitative vs quantitative vs categorical Three variables If day_of_week and date both explain some of the variability in births, why not include both in our analysis?! Let’s. Note how the code changes. # births vs date ggplot(only_2014, aes(y = births, x = date)) + geom_point() # births vs day_of_week ggplot(only_2014, aes(x = births, fill = day_of_week)) + geom_density(alpha=0.5) # births vs date AND day_of_week ggplot(only_2014, aes(y = births, x = date, color = day_of_week)) + geom_point() Visualize the trend Finally, let’s visualize the birth trends from 2000-2014. # add trend lines ggplot(birth_data, aes(y = births, x = date, color = day_of_week)) + geom_point() + geom_smooth() # change the smoothness ggplot(birth_data, aes(y = births, x = date, color = day_of_week)) + geom_point() + geom_smooth(span = 0.1) Summarize Summarize what you’ve learned about birth patterns. In what month do the most babies tend to be born? The least? On what day of week do the most babies tend to be born? The least? In what year were the most babies born? The least? What explains the outliers in the dataset? 3.5 Exercises In the exercises, you’ll return to the Bechdel test data: library(fivethirtyeight) data(bechdel) dim(bechdel) ## [1] 1794 15 Solutions are provided below. 3.5.1 Questions Visualizing a categorical variable The categorical binary variable records whether each film in the dataset passes or fails the Bechdel test: levels(factor(bechdel$binary)) A bar chart provides a simple visualization of this variable. Summarize what you learn from this plot: roughly how many of the films pass / fail the test? # Bar plot ggplot(bechdel, aes(x = binary)) + geom_bar() Visualize potential “predictors” Our ultimate goal will be to better understand which films pass / fail the Bechdel test. For example, can this be explained the year in which it was made? The film’s budget? The amount of money it makes at the box office? Before we can answer these questions, it’s important to understand the scales of these variables. For each variable below, construct and summarize a univariate visualization. year: the year in which the film was released budget_2013: the film’s budget (in 2013 $) domgross_2013: the film’s total domestic gross (in 2013 $) binary vs x To answer each question below, construct and summarize a visualization between the given pair of variables. The hints below apply in each scenario. Is there a relationship between the year in which a film is made and whether is passes the Bechdel (binary)? Do movies that pass the Bechdel test tend to receive more or less funding (as measured by budget_2013) than those that fail the test? Do movies that pass the Bechdel test tend to make more or less money (as measured by domgross_2013) than those that fail the test? Hints Is binary categorical or quantitative? What about the other variable? Thus what visualization tool might you use? Fill in the following: ggplot(___, aes(x = ___, y = ___)) + ___() binary vs x1 and x2 For each question below, construct and summarize a helpful visualization that includes a geom_smooth(). How have the budgets (budget_2013) of films that pass / fail the Bechdel test (binary) changed and compared over time (year)? HINT: Put year on the x-axis. How have the gross profits (domgross_2013) of films that pass / fail the Bechdel test (binary) changed and compared over time (year)? HINT: Put year on the x-axis. How does the “return on investment” compare for films that pass / fail the Bechdel test? Specifically, examine the relationship between domgross_2013 and budget_2013 for films that pass / fail the Bechdel test (binary). HINT: Put budget_2013 on the x-axis. Extra: identify the outliers By now, you’ve seen some outliers in your visualizations. Try to identify these by subsetting the bechdel data. Extra visualization practice Bike sharing is becoming a more popular means of transportation in many cities. The dataset we will analyze in this assignment comes from Capital Bikeshare, the bike-sharing service for the Washington DC area. The dataset originally comes from the UCI Machine Learning Repository and the version we’ll work with is made available at Macalester Prof Shuman’s website: bikes &lt;- read.csv(&quot;https://www.macalester.edu/~dshuman1/data/155/bike_share.csv&quot;) Codebook variable meaning date date in format YYYY-MM-DD season winter, spring, summer, or fall year 2011 or 2012 month 3-letter month abbreviation day_of_week 3-letter abbreviation for day of week weekend TRUE if the case is a weekend, FALSE otherwise holiday is the day a holiday? (yes or no) temp_actual temperature in degrees Fahrenheit temp_feel what the temperature feels like in degrees Fahrenheit humidity fraction from 0 to 1 giving the humidity level windspeed wind speed in miles per hour weather_cat categ1: clear to partly cloudy categ2: mist + some clouds categ3: light precipitation to thunderstorms riders_casual count of daily rides by casual users (non-registered users) riders_registered count of daily rides by registered users riders_total count of total daily rides (riders_casual + riders_registered) Utilize visualizations to better understand how riders_registered might depend upon windspeed, temp_feel, weekend, or season. 3.5.2 Solutions More films fail than pass the Bechdel test (~1000 vs ~800). ggplot(bechdel, aes(x = binary)) + geom_bar() . # a ggplot(bechdel, aes(x = year)) + geom_histogram(color = &quot;white&quot;) ggplot(bechdel, aes(x = year)) + geom_density() # b ggplot(bechdel, aes(x = budget_2013)) + geom_histogram(color = &quot;white&quot;) ggplot(bechdel, aes(x = budget_2013)) + geom_density() # c ggplot(bechdel, aes(x = domgross_2013)) + geom_histogram(color = &quot;white&quot;) ggplot(bechdel, aes(x = domgross_2013)) + geom_density() Over time, more films have been passing the Bechdel test. Further, films that fail the Bechdel tend to have bigger budgets and to make more money. # a ggplot(bechdel, aes(x = year, fill = binary)) + geom_density(alpha = 0.5) ggplot(bechdel, aes(x = binary, y = year)) + geom_boxplot() # b ggplot(bechdel, aes(x = budget_2013, fill = binary)) + geom_density(alpha = 0.5) ggplot(bechdel, aes(x = binary, y = budget_2013)) + geom_boxplot() # c ggplot(bechdel, aes(x = domgross_2013, fill = binary)) + geom_density(alpha = 0.5) ggplot(bechdel, aes(x = binary, y = domgross_2013)) + geom_boxplot() . # a ggplot(bechdel, aes(x = year, y = budget_2013, color = binary)) + geom_point() + geom_smooth() # b ggplot(bechdel, aes(x = year, y = domgross_2013, color = binary)) + geom_point() + geom_smooth() # c ggplot(bechdel, aes(x = budget_2013, y = domgross_2013, color = binary)) + geom_point() + geom_smooth() For example, we can i.d. the film that made the most money: library(dplyr) bechdel %&gt;% filter(domgross_2013 &gt; 1500000000) ## # A tibble: 1 x 15 ## year imdb title test clean_test binary budget domgross intgross code ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;ord&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1977 tt00… Star… nota… notalk FAIL 1.10e7 4.61e8 7.98e8 1977… ## # … with 5 more variables: budget_2013 &lt;int&gt;, domgross_2013 &lt;dbl&gt;, ## # intgross_2013 &lt;dbl&gt;, period_code &lt;int&gt;, decade_code &lt;int&gt; Choose your own adventure! Here are some ideas: # rides vs windspeed ggplot(bikes, aes(y = riders_registered, x = windspeed)) + geom_point() + geom_smooth() # rides vs temperature ggplot(bikes, aes(y = riders_registered, x = temp_feel)) + geom_point() + geom_smooth() # rides by weekend ggplot(bikes, aes(y = riders_registered, x = weekend)) + geom_boxplot() # rides by season ggplot(bikes, aes(y = riders_registered, x = season)) + geom_boxplot() # rides by windspeed and weekend ggplot(bikes, aes(y = riders_registered, x = windspeed, color = weekend)) + geom_point() + geom_smooth() # EXTRA: rides by season and weekend ggplot(bikes, aes(y = riders_registered, x = season, fill = weekend)) + geom_boxplot() # EXTRA: rides by windspeed and temperature ggplot(bikes, aes(y = riders_registered, x = windspeed, color = temp_feel)) + geom_point() ggplot(bikes, aes(y = riders_registered, x = windspeed, size = temp_feel)) + geom_point() "],
["understanding-data-transformations.html", " 4 Understanding data: Transformations 4.1 Goal: Understanding Through Transformations 4.2 dplyr 4.3 Transforming rows: arrange() and filter() 4.4 Transforming columns: select() and mutate() 4.5 Simple numerical summaries: summarize() 4.6 Exercises", " 4 Understanding data: Transformations Author: Alicia Johnson 4.1 Goal: Understanding Through Transformations In this module we’ll focus on the “Transform” step within the data science workflow: source: Wickham &amp; Grolemund: R for Data Science In the previous modules, we imported and visualized tidy data. These visualizations provided us with important insights into the patterns in our data. Data transformations are also fundamental to understanding data: We can utilize data transformations to: define &amp; explore new variables; filter &amp; focus on subsets of the data; reorder the data. Simple numerical summaries calculated via data transformations complement, formalize, and support the patterns observed in our visual summaries. 4.2 dplyr We’ll construct data transformations using the dplyr package: library(dplyr) Like ggplot, the dplyr “grammar” is intuitive and generalizable once mastered. The best way to learn about dplyr is to just play around. Don’t worry about memorizing the syntax. Rather, focus on the patterns and potential of their application. There’s a helpful cheat sheet for future reference: DPLYR CHEAT SHEET In the dplyr grammar, there are 5 verbs (actions): arrange() = reorder the rows filter() = take a subset of rows select() = take a subset of columns mutate() = create a new variable, ie. column summarize() = calculate a numerical summary of a variable, i.e. column The general syntax for applying these verbs is below, where we call “%&gt;%” a “pipe”: my_dataset %&gt;% verb(___) Just as we can add layers to a ggplot utilizing “+”, we can implement sequential data transformations utilizing “`%&gt;%”: my_dataset %&gt;% verb1(___) %&gt;% verb2(___) 4.3 Transforming rows: arrange() and filter() The fivethirtyeight article The Ultimate Halloween Candy Power Ranking analyzes the data from this experiment which presented subjects with a series of head-to-head candy matchups and asked them to indicate which candy they preferred. Import these tidy data from the fivethirtyeight package: # Load the package library(fivethirtyeight) # Load the data data(&quot;candy_rankings&quot;) # Give the data frame a shorter name candy &lt;- candy_rankings Basics # Take a glimpse at the data. What&#39;s the unit of observation? # How much data do we have? arrange() rows Right now, the order of the rows / candy is somewhat arbitrary. We can arrange() the rows in a more meaningful way: # Arrange from least to most popular candy %&gt;% arrange(winpercent) candy %&gt;% arrange(winpercent) %&gt;% head() # Arrange from most to least popular candy %&gt;% arrange(desc(winpercent)) candy %&gt;% arrange(desc(winpercent)) %&gt;% head() # You try: arrange from least to most expensive # You try: arrange from most to least expensive filter() rows We’re not always interested in all rows of a dataset. For example, here we might be interested in studying only chocolate, not all candy. filter() allows us to keep only certain rows that meet a given criterion. To write these criteria, we must specify the variable by which we want to filter the data and the value(s) of that variable that we want to keep. Here are some general rules to try out below: If variable x is quantitative: x == 1, x &lt; 1, x &lt;= 1, x &gt; 1, x &gt;= 1, x != 1 If variable x is categorical / factor: x == &quot;a&quot;, x != &quot;a&quot; If variable x is logical (TRUE / FALSE): x == TRUE, x == FALSE # Keep the sad candies that won less than 30% candy %&gt;% filter(___) # Keep only Dots candy %&gt;% filter(___) # Keep only chocolate-y candies candy %&gt;% filter(___) Combining arrange() and filter() We can perform multiple sequential arrange() and filter() operations. # Keep only chocolate-y, peanut butter-y candies. Do this in 3 lines. candy %&gt;% filter(___) %&gt;% filter(___) # Keep only chocolate-y, peanut butter-y candies. Do this in 2 lines. candy %&gt;% filter(___, ___) # Arrange fruity candy from most to least popular candy %&gt;% ___(___) %&gt;% ___(___) 4.4 Transforming columns: select() and mutate() select() columns There are often more variables (columns) in a dataset than we’re interested in. Keeping these in the dataset doesn’t hurt anything, but removing them can make data analysis more manageable and less overwhelming. # Create a dataset which only contains candy name &amp; winpercent candy %&gt;% select(competitorname, winpercent) %&gt;% head() # You try: create a dataset which only contains candy name, chocolate status, &amp; winpercent mutate() columns We can create new variables (columns) by mutating existing columns. This is helpful when we want to change the scale of a variable, combine variables into new measurements, etc. # Create price_percentile variable which transforms pricepercent to 0-100 scale candy %&gt;% mutate(price_percentile = ___) %&gt;% head() # You try: create fruity_hard variable which indicates whether candy is fruity AND hard 4.5 Simple numerical summaries: summarize() Review: univariate visualizations Construct a univariate visualization of winpercent. Summarize the trend and variability in the winpercent from candy to candy. Univariate numerical summaries of trend and variability The visualization above allows us to eyeball the trend and variability in winpercent. We can support these observations with rigorous numerical summaries. # Trend: calculate the mean winpercent candy %&gt;% summarize(mean(winpercent)) # Trend: calculate the mean &amp; median winpercent candy %&gt;% summarize(mean(winpercent), median(winpercent)) # Variability: calculate the min &amp; max winpercent candy %&gt;% summarize(___, ___) Review: multivariate visualizations Construct a visualization of the relationship between winpercent and chocolate. Summarize your observations. Numerical summaries by group The visualization above illuminates how the trend and variability in winpercent differs depending upon chocolate status. We can calculate separate numerical summaries for these groups. # Trend: calculate the mean winpercent by chocolate group candy %&gt;% group_by(chocolate) %&gt;% summarize(mean(winpercent)) # (You try) Variability: calculate the min &amp; max winpercent by chocolate group 4.6 Exercises Practice, practice, practice is important when learning the dplyr verbs. Try out the following exercises with solutions below. 4.6.1 Questions Revisiting movies Recall the bechdel data: data(&quot;bechdel&quot;) To simplify our analysis, create a new dataset named new_bechdel which contains only the following variables: title, year, binary, clean_test, budget_2013, domgross_2013. HINT: Which verb is helpful here: arrange(), filter(), select(), mutate(), summarize() new_bechdel &lt;- ___ Transforming budget and gross Film budgets and profits can be huge. To make these values easier to explore, create two new variables, budget_mil and gross_mil, which transform budget_2013 and domgross_2013 to the millions scale (instead of $ scale). Be sure to store these in the new_bechdel dataset. HINT: Which verb is helpful here: arrange(), filter(), select(), mutate(), summarize() new_bechdel &lt;- ___ Most vs least expensive. Most vs least profitable Identify the 6 movies with the largest budgets and the 6 movies with the smallest budgets. Identify the 6 movies with the largest gross and the 6 movies with the smallest gross. Among films that pass the Bechdel test, which are the 6 with the largest gross? HINT: You’ll need to combine 2 dplyr verbs! Which films? Identify which films were… Made in 2013. Made in 2013 and didn’t pass the “at least 2 women characters” criterion of the Bechdel test. HINT: This is indicated by the nowomen level of the clean_test variable. Made in 2013 and grossed more than $300,000,000. Min, Median, Max Among all films in the dataset, calculate the minimum, median, and maximum budget. Among all films in the dataset, calculate and compare the minimum, median, and maximum budgets for movies that pass and fail the Bechdel test. Among films made in the 1970s, calculate and compare the minimum, median, and maximum budgets for movies that pass and fail the Bechdel test. Among films made in the 2010s, calculate and compare the minimum, median, and maximum budgets for movies that pass and fail the Bechdel test. Compare your results for parts c and d. What does this reveal about changes in the movie business? Challenge: Friday the 13th In this final exercise, you’ll need to combine some of the dplyr verbs in a more open-ended scenario. Hints are provided below. Recall the US_births_2000_2014 births data: data(&quot;US_births_2000_2014&quot;) We’ll use these data to determine whether there’s any evidence that people are superstitious about giving birth on Friday the 13th. Specifically: Visualize the birth patterns among Fridays that fall on the 13th day of the month and Fridays that fall off the 13th day. Calculate and compare the median number of births on Fridays that fall on the 13th vs Fridays that fall off the 13th. Summarize your findings. Mainly, did you find ample evidence of superstition? HINTS: We’re only interested in births that occur on Fridays. There’s currently no variable that lumps Friday birthdays into two categories: those that fall on the 13th day of the month and those that don’t. 4.6.2 Solutions . data(&quot;bechdel&quot;) new_bechdel &lt;- bechdel %&gt;% select(title, year, binary, clean_test, budget_2013, domgross_2013) . new_bechdel &lt;- new_bechdel %&gt;% mutate(budget_mil = budget_2013 / 1000000, gross_mil = domgross_2013 / 1000000) . # a new_bechdel %&gt;% arrange(desc(budget_mil)) %&gt;% head() ## # A tibble: 6 x 8 ## title year binary clean_test budget_2013 domgross_2013 budget_mil ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Avat… 2009 FAIL men 461435929 825707158 461. ## 2 Pira… 2007 PASS ok 337063045 347647302 337. ## 3 Shaft 1971 FAIL notalk 305063707 404702718 305. ## 4 Tita… 1997 PASS ok 290247625 955890356 290. ## 5 John… 2012 PASS ok 279025606 74128153 279. ## 6 The … 2012 FAIL notalk 279025606 454699213 279. ## # … with 1 more variable: gross_mil &lt;dbl&gt; new_bechdel %&gt;% arrange(budget_mil) %&gt;% head() ## # A tibble: 6 x 8 ## title year binary clean_test budget_2013 domgross_2013 budget_mil ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Prim… 2004 FAIL notalk 8632 523811 0.00863 ## 2 El M… 1992 FAIL nowomen 11622 3388636 0.0116 ## 3 In t… 1997 FAIL notalk 36281 4184879 0.0363 ## 4 Funn… 2002 PASS ok 38855 99819 0.0389 ## 5 Slac… 1991 PASS ok 39349 2100070 0.0393 ## 6 Cler… 1994 FAIL notalk 42435 4830398 0.0424 ## # … with 1 more variable: gross_mil &lt;dbl&gt; # b new_bechdel %&gt;% arrange(desc(gross_mil)) %&gt;% head() ## # A tibble: 6 x 8 ## title year binary clean_test budget_2013 domgross_2013 budget_mil ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Star… 1977 FAIL notalk 42274609 1771682790 42.3 ## 2 Jaws 1975 FAIL notalk 51937204 1125306085 51.9 ## 3 The … 1973 PASS ok 62926730 1074306128 62.9 ## 4 E.T.… 1982 FAIL dubious 25339314 1050038377 25.3 ## 5 Tita… 1997 PASS ok 290247625 955890356 290. ## 6 The … 1973 FAIL notalk 28841418 837011132 28.8 ## # … with 1 more variable: gross_mil &lt;dbl&gt; new_bechdel %&gt;% arrange(gross_mil) %&gt;% head() ## # A tibble: 6 x 8 ## title year binary clean_test budget_2013 domgross_2013 budget_mil ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Perr… 2009 FAIL nowomen 7165829 899 7.17 ## 2 Pont… 2008 FAIL nowomen 1623384 4183 1.62 ## 3 Supp… 2012 FAIL men 60878 4989 0.0609 ## 4 Trop… 2007 PASS ok 7345604 9824 7.35 ## 5 St. … 2007 PASS ok 12808396 16853 12.8 ## 6 The … 2011 PASS ok 3107072 18642 3.11 ## # … with 1 more variable: gross_mil &lt;dbl&gt; # c new_bechdel %&gt;% filter(binary == &quot;PASS&quot;) %&gt;% arrange(desc(gross_mil)) %&gt;% head() ## # A tibble: 6 x 8 ## title year binary clean_test budget_2013 domgross_2013 budget_mil ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 The … 1973 PASS ok 62926730 1074306128 62.9 ## 2 Tita… 1997 PASS ok 290247625 955890356 290. ## 3 Star… 1999 PASS ok 160823133 663632711 161. ## 4 Grea… 1978 PASS ok 21424236 649203517 21.4 ## 5 Jura… 1993 PASS ok 101584911 638063379 102. ## 6 Shre… 2004 PASS ok 86323501 544117065 86.3 ## # … with 1 more variable: gross_mil &lt;dbl&gt; . # a new_bechdel %&gt;% filter(year == 2013) %&gt;% head() # just for simplicity ## # A tibble: 6 x 8 ## title year binary clean_test budget_2013 domgross_2013 budget_mil ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 &amp;… 2013 FAIL notalk 13000000 25682380 13 ## 2 12 Y… 2013 FAIL notalk 20000000 53107035 20 ## 3 2 Gu… 2013 FAIL notalk 61000000 75612460 61 ## 4 42 2013 FAIL men 40000000 95020213 40 ## 5 47 R… 2013 FAIL men 225000000 38362475 225 ## 6 A Go… 2013 FAIL notalk 92000000 67349198 92 ## # … with 1 more variable: gross_mil &lt;dbl&gt; # b new_bechdel %&gt;% filter(year == 2013, clean_test == &quot;nowomen&quot;) ## # A tibble: 6 x 8 ## title year binary clean_test budget_2013 domgross_2013 budget_mil ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Clou… 2013 FAIL nowomen 78000000 119640264 78 ## 2 Grav… 2013 FAIL nowomen 110000000 271814796 110 ## 3 Jack… 2013 FAIL nowomen 195000000 65187603 195 ## 4 Runn… 2013 FAIL nowomen 30000000 19316646 30 ## 5 The … 2013 FAIL nowomen 19200000 NA 19.2 ## 6 Tran… 2013 FAIL nowomen 16000000 2322593 16 ## # … with 1 more variable: gross_mil &lt;dbl&gt; # c new_bechdel %&gt;% filter(year == 2013, gross_mil &gt; 300) ## # A tibble: 4 x 8 ## title year binary clean_test budget_2013 domgross_2013 budget_mil ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Desp… 2013 PASS ok 76000000 368065385 76 ## 2 Froz… 2013 PASS ok 150000000 393050114 150 ## 3 Iron… 2013 FAIL dubious 200000000 408992272 200 ## 4 The … 2013 PASS ok 130000000 424088260 130 ## # … with 1 more variable: gross_mil &lt;dbl&gt; . # a new_bechdel %&gt;% summarize(min(budget_mil), median(budget_mil), max(budget_mil)) ## # A tibble: 1 x 3 ## `min(budget_mil)` `median(budget_mil)` `max(budget_mil)` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.00863 37.0 461. # b new_bechdel %&gt;% group_by(binary) %&gt;% summarize(min(budget_mil), median(budget_mil), max(budget_mil)) ## # A tibble: 2 x 4 ## binary `min(budget_mil)` `median(budget_mil)` `max(budget_mil)` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 FAIL 0.00863 44.0 461. ## 2 PASS 0.0389 31.5 337. # c new_bechdel %&gt;% filter(year &lt; 1980) %&gt;% group_by(binary) %&gt;% summarize(min(budget_mil), median(budget_mil), max(budget_mil)) ## # A tibble: 2 x 4 ## binary `min(budget_mil)` `median(budget_mil)` `max(budget_mil)` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 FAIL 0.384 20.7 305. ## 2 PASS 0.0669 22.2 62.9 # d new_bechdel %&gt;% filter(year &gt;= 2010) %&gt;% group_by(binary) %&gt;% summarize(min(budget_mil), median(budget_mil), max(budget_mil)) ## # A tibble: 2 x 4 ## binary `min(budget_mil)` `median(budget_mil)` `max(budget_mil)` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 FAIL 0.0609 46.6 279. ## 2 PASS 0.0534 26.9 279. . data(&quot;US_births_2000_2014&quot;) # Filter out all but Fridays and define Friday the 13th variable new_births &lt;- US_births_2000_2014 %&gt;% filter(day_of_week == &quot;Fri&quot;) %&gt;% mutate(fri13 = (date_of_month == 13)) # a ggplot(new_births, aes(x = births, fill = fri13)) + geom_density(alpha = 0.5) # b new_births %&gt;% group_by(fri13) %&gt;% summarize(median(births)) ## # A tibble: 2 x 2 ## fri13 `median(births)` ## &lt;lgl&gt; &lt;int&gt; ## 1 FALSE 12656 ## 2 TRUE 11994 "]
]
